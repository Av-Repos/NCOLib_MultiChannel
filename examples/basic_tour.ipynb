{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('.'))\n",
    "\n",
    "import random\n",
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nco_lib.environment.actions import two_opt, bit_flip, insert, swap\n",
    "from nco_lib.environment.env import State, Env, ConstructiveStoppingCriteria, ConstructiveReward, ImprovementReward, ImprovementStoppingCriteria\n",
    "from nco_lib.environment.problem_def import ConstructiveProblem, ImprovementProblem\n",
    "from nco_lib.models.graph_transformer import GTModel, EdgeInGTModel, EdgeInOutGTModel\n",
    "from nco_lib.data.data_loader import generate_random_graph\n",
    "from nco_lib.trainer.trainer import ConstructiveTrainer, ImprovementTrainer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Simple Tutorial\n",
    "We will show how to use the library to solve combinatorial optimization problems using reinforcement learning.\n",
    "\n",
    "First, we define the problem by inheriting from the ConstructiveProblem or ImprovementProblem class. We need to implement the following methods:\n",
    "- **_init_instances**: Initialize the problem instances (graphs).\n",
    "- **_init_solutions**: Initialize the solutions (to empty solutions if we are using a constructive method or to a complete solution if we are using an improvement method).\n",
    "- **_init_features**: Initialize the node- and edge-features.\n",
    "- **_init_mask** (optional): Initialize the mask, to mask certain actions. Only if it is required by the problem constraints.\n",
    "- **_obj_function**: Compute the objective function value.\n",
    "- **_update_features**: Update the node features based on the selected action.\n",
    "- **_update_solutions**: Update the solutions based on the selected action.\n",
    "- **_update_mask** (optional): Update the mask based on the selected action in previous step.\n",
    "- **_check_completeness**: Check if the solution is complete. This function is required for constructive problems to check if the solution, and therefore the episode, is completed.\n",
    "\n",
    "The State class is used to store the problem instances, solutions, features, mask, and other useful information such as the device and batch size. The user can add any other data that is required for the problem definition in the state.data dictionary."
   ],
   "id": "4e1f6fa6ab27d3ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Constructive Problem\n",
    "The following image represents the pipeline followed in a constructive problem: \n",
    "- First the instances, solutions, features, and mask are initialized and fed to the model in the state. \n",
    "- Then, the model predicts the actions based on the state. \n",
    "- The actions are used to update the solutions, features, and mask. \n",
    "- The objective function is computed based on the updated solutions and is used to compute the reward given to the model in order to update its weights. \n",
    "- The process is repeated until the episode is completed.\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "    <img src=\"../docs/constructive_pipeline.png\" alt=\"Constructive Pipeline\" title=\"Constructive Pipeline\"/>\n",
    "</p>"
   ],
   "id": "87fb710fea25bed1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here is an example of a dummy constructive problem:",
   "id": "83cf815fce65049b"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# 1) Define the constructive problem\n",
    "class SimpleConstructiveProblem(ConstructiveProblem):\n",
    "    def _init_instances(self, state: State) -> State:\n",
    "        # Here you need to initialize the problem instances (graphs) and any other data required for computing the objective value, calculating the mask or checking completeness\n",
    "        # The state class already has the batch size, the problem size, random seed and used device in here, so you can use them to initialize the instances\n",
    "        \n",
    "        # You can create the adjacency matrix randomly by using the generate_random_graph function\n",
    "        state.adj_matrix = generate_random_graph(state.batch_size, state.problem_size, state.seed, edge_prob=0.15, device=state.device)\n",
    "        \n",
    "        # You can also add any other useful information in the state.data dictionary\n",
    "        state.data['useful_info'] = torch.rand(state.batch_size, state.problem_size, state.problem_size, device=state.device)\n",
    "        \n",
    "        # Return the state, do not change this\n",
    "        return state\n",
    "\n",
    "    def _init_solutions(self, state: State) -> State:\n",
    "        # Initialize the solutions, in constructive problems the solutions are initialized to empty solutions.\n",
    "        # Remember to use state.batch_size, state.problem_size and state.device to initialize the solutions\n",
    "        state.solutions = torch.zeros((state.batch_size, state.problem_size), device=state.device)\n",
    "        return state\n",
    "\n",
    "    def _init_features(self, state: State) -> State:\n",
    "        # Initialize the node features, these can be computed based on state.data, state.solutions and state.adj_matrix. Dummy example:\n",
    "        state.node_features = state.data['useful_info'] + state.adj_matrix.sum(2, keepdim=True) + state.solutions\n",
    "        return state\n",
    "\n",
    "    def _init_mask(self, state: State) -> State:\n",
    "        # Initialize the mask. This is optional, only if the problem requires masking certain actions. \n",
    "        # Otherwise, you can return state or the following code, which initializes the mask to zeros:\n",
    "        state.mask = torch.zeros((state.batch_size, state.problem_size, 1), device=state.device)\n",
    "        return state\n",
    "\n",
    "    def _obj_function(self, state: State) -> torch.Tensor:\n",
    "        # Compute the objective function. This is used to compute the reward for the model. \n",
    "        # Here you can also use state.data, state.solutions and state.adj_matrix. \n",
    "        # This is the only function that do not return a state. \n",
    "        # Instead, it returns the objective function values for each instance in the batch in a tensor.\n",
    "        return state.solutions.sum(1)\n",
    "\n",
    "    def _update_features(self, state: State) -> State:\n",
    "        # Update the node features, is this is equal to the _init_features method, then you can call it directly by returning self._init_features(state)\n",
    "        return self._init_features(state)\n",
    "\n",
    "    def _update_solutions(self, state: State, action: torch.Tensor) -> State:\n",
    "        # Update the solutions using the action predicted by the model\n",
    "        # In node-based constructive problems, the action is the node index to be selected, so the action is a tensor of shape (batch_size, n_classes), where n_classes is the number of output classes.\n",
    "        # In edge-based constructive problems, the action is the edge index to be selected, so the action is a tensor of shape (batch_size, n_classes, 2), where n_classes is the number of output classes.\n",
    "        state.solutions = state.solutions + action\n",
    "        return state\n",
    "\n",
    "    def _update_mask(self, state: State, action: torch.Tensor) -> State:\n",
    "        # Update the mask. In constructive problems, each node is selected just once, so you can mask the selected nodes. \n",
    "        # Remember to mask it with -inf.\n",
    "        batch_range = torch.arange(state.batch_size, device=state.device)\n",
    "        state.mask[batch_range, action, :] = float('-inf')\n",
    "        return state\n",
    "\n",
    "    def _check_completeness(self, state: State) -> State:\n",
    "        # Check if the solution is complete. \n",
    "        # This is required for constructive problems to check if the solution, and therefore the episode, is completed.\n",
    "        # In improvement methods, if all the steps are completed, then you can set state.is_complete = True.\n",
    "        state.is_complete = (state.solutions == 0).sum() == 0\n",
    "        # state.is_complete = True  # Uncomment this line if the solution is complete in every step.\n",
    "        return state"
   ],
   "id": "df5a330a02fb1201",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Example for the Traveling Salesman Problem (TSP), training a constructive model\n",
    "1) Define the TSP constructive problem\n",
    "2) Define the environment, the model, and the trainer\n",
    "3) Run training and inference"
   ],
   "id": "6ff5041fdb60edb6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1) Define the TSP constructive problem\n",
    "class TSPConstructiveProblem(ConstructiveProblem):\n",
    "    def _init_instances(self, state: State) -> State:\n",
    "        \"\"\"\n",
    "        Here the user can define the generation of the instances for the TSP problem.\n",
    "        These instances will be later used to define the node/edge features.\n",
    "        The state class supports the adjacency matrix as a default data field.\n",
    "        If any other data is needed, it should be stored in the state.data dictionary as done with the coordinates.\n",
    "        The instances will generally have a shape of (batch_size, problem_size, problem_size, n) or (batch_size, problem_size, n), where n is the number of features.\n",
    "        \"\"\"\n",
    "        if state.seed is not None:\n",
    "            torch.manual_seed(state.seed)\n",
    "\n",
    "        # Generate the city coordinates as user-defined data\n",
    "        state.data['coords'] = torch.rand(state.batch_size, state.problem_size, 2, device=state.device)\n",
    "\n",
    "        # One could also define the Euclidean distances to later be used as edge features\n",
    "        return state\n",
    "\n",
    "    def _init_solutions(self, state: State) -> State:\n",
    "        \"\"\"\n",
    "        Here the user can define the initialization of the solutions for the TSP problem.\n",
    "        In constructive methods, the solutions are generally initialized empty.\n",
    "        However, for the TSP, we can select a random city as the starting point.\n",
    "        In fact, the user can initialize multiple constructions per instance (with POMO).\n",
    "        The solution will generally have a shape of (batch_size, pomo_size, 0~problem_size).\n",
    "        \"\"\"\n",
    "\n",
    "        # We will set random city initializations from 0 to problem_size-1 (problem size is the number of cities)\n",
    "        state.solutions = torch.randint(0, state.problem_size, (state.batch_size, state.pomo_size, 1), device=state.device)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _init_features(self, state: State) -> State:\n",
    "        \"\"\"\n",
    "        Here the user can define the initialization of the node features for the TSP problem.\n",
    "\n",
    "        For the TSP, we will use the coordinates, whether the city is selected or not, and whether it is the first or last city in a one-hot encoding.\n",
    "        In this case, the node features will have a shape of (batch_size, pomo_size, problem_size, n), where n is the number of features.\n",
    "        \"\"\"\n",
    "        # Initialize indices for batch and POMO dimensions\n",
    "        batch_range = torch.arange(state.batch_size, device=state.device)[:, None].expand(state.batch_size, state.pomo_size)\n",
    "        pomo_range = torch.arange(state.pomo_size, device=state.device)[None, :].expand(state.batch_size, state.pomo_size)\n",
    "        batch_indices = torch.arange(state.batch_size, device=state.device)[:, None, None].expand(state.batch_size, state.pomo_size, state.solutions.size(1))\n",
    "        pomo_indices = torch.arange(state.pomo_size, device=state.device)[None, :, None].expand(state.batch_size, state.pomo_size, state.solutions.size(1))\n",
    "\n",
    "        # Create the coordinates for each city, expanded for the POMO dimension\n",
    "        pomo_coords = state.data['coords'].unsqueeze(1).expand(state.batch_size, state.pomo_size, state.problem_size, 2)\n",
    "\n",
    "        # One hot encoding for the selected cities: selected (0, 1) and non-selected (1, 0)\n",
    "        selected = torch.zeros(state.batch_size, state.pomo_size, state.problem_size, 2, device=device)\n",
    "        selected[batch_range, pomo_range, :, 0] = 1\n",
    "        selected[batch_indices, pomo_indices, state.solutions.long(), 0] = 0\n",
    "        selected[batch_indices, pomo_indices, state.solutions.long(), 1] = 1\n",
    "\n",
    "        # One hot encoding for the first cities\n",
    "        first_selected = torch.zeros(state.batch_size, state.pomo_size, state.problem_size, 1, device=device)\n",
    "        first_selected[batch_range, pomo_range, state.solutions[:, :, 0].long(), 0] = 1\n",
    "\n",
    "        # One hot encoding for the last cities\n",
    "        last_selected = torch.zeros(state.batch_size, state.pomo_size, state.problem_size, 1, device=device)\n",
    "        last_selected[batch_range, pomo_range, state.solutions[:, :, -1].long(), 0] = 1\n",
    "\n",
    "        # Concatenate the features\n",
    "        state.node_features = torch.cat([pomo_coords, selected, first_selected, last_selected], dim=-1)\n",
    "        return state\n",
    "\n",
    "    def _init_mask(self, state: State) -> State:\n",
    "        \"\"\"\n",
    "        Here the user can define the initialization of the mask.\n",
    "        In the TSP, the mask will be used to prevent the model from selecting the same city multiple times.\n",
    "        Therefore, we need to mask the selected cities for each construction.\n",
    "        \"\"\"\n",
    "\n",
    "        # Use POMO: Mask the selected cities for each construction\n",
    "        batch_range = torch.arange(state.batch_size, device=state.device)[:, None].expand(state.batch_size, state.pomo_size)\n",
    "        pomo_range = torch.arange(state.pomo_size, device=state.device)[None, :].expand(state.batch_size, state.pomo_size)\n",
    "\n",
    "        # Get the selected cities from the POMO solutions\n",
    "        action = state.solutions.squeeze(2)\n",
    "\n",
    "        # Initialize the mask to zeros\n",
    "        state.mask = torch.zeros((state.batch_size, state.pomo_size, state.problem_size, 1), device=state.device)\n",
    "\n",
    "        # Mask the selected cities\n",
    "        state.mask[batch_range, pomo_range, action, :] = float('-inf')\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _obj_function(self, state: State) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        In this function, the user needs to define the objective function for the TSP problem.\n",
    "        This function is called only once the solution is completed.\n",
    "        \"\"\"\n",
    "\n",
    "        gathering_index = state.solutions.unsqueeze(3).expand(state.batch_size, -1, state.problem_size, 2)\n",
    "        # shape: (batch, pomo, problem, 2)\n",
    "\n",
    "        seq_expanded = state.data['coords'][:, None, :, :].expand(state.batch_size, state.pomo_size, state.problem_size, 2)\n",
    "        # shape: (batch, pomo, problem, 2)\n",
    "\n",
    "        ordered_seq = seq_expanded.gather(dim=2, index=gathering_index)\n",
    "        # shape: (batch, pomo, problem, 2)\n",
    "\n",
    "        rolled_seq = ordered_seq.roll(dims=2, shifts=-1)\n",
    "        segment_lengths = ((ordered_seq-rolled_seq)**2).sum(3).sqrt()\n",
    "        # shape: (batch, pomo, problem)\n",
    "\n",
    "        travel_distances = segment_lengths.sum(2)\n",
    "\n",
    "        return -travel_distances  # minimize the total distance  -> maximize the negative distance\n",
    "\n",
    "    def _update_features(self, state: State, action: Tuple[torch.Tensor, torch.Tensor]) -> State:\n",
    "        \"\"\"\n",
    "        This function is used to define how to update the node/edge features based on the new partial solutions.\n",
    "        \"\"\"\n",
    "        # Initialize indices for batch and POMO dimensions\n",
    "        batch_indices = torch.arange(state.batch_size, device=state.device)[:, None, None].expand(state.batch_size, state.pomo_size, state.solutions.size(1))\n",
    "        pomo_indices = torch.arange(state.pomo_size, device=state.device)[None, :, None].expand(state.batch_size, state.pomo_size, state.solutions.size(1))\n",
    "\n",
    "        # Only update the selected and last visited cities\n",
    "        action = action[0]\n",
    "\n",
    "        # Selected (0, 1) and non-selected (1, 0), modify from (1, 0) to (0, 1) for the selected cities\n",
    "        node_features = state.node_features.clone()\n",
    "        node_features[batch_indices, pomo_indices, action.unsqueeze(2), 2] = 0\n",
    "\n",
    "        node_features[batch_indices, pomo_indices, action.unsqueeze(2), 3] = 1\n",
    "\n",
    "        # Update the node features\n",
    "        state.node_features = node_features\n",
    "\n",
    "        # Last visited feature to 0\n",
    "        state.node_features[batch_indices, pomo_indices, :, 5] = 0\n",
    "\n",
    "        # Update the last visited city\n",
    "        state.node_features[batch_indices, pomo_indices, action.unsqueeze(2), 5] = 1\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _update_solutions(self, state: State, action: Tuple[torch.Tensor, torch.Tensor]) -> State:\n",
    "        \"\"\"\n",
    "        This function is used to update the solutions based on the selected actions.\n",
    "        Actions are given in a tuple format, where the first part is the selected node and the second part is the selected class.\n",
    "        In the case of the TSP, we only need the selected node; this is equivalent to having a single class.\n",
    "        Therefore, only the first part of the action tuple is used.\n",
    "        \"\"\"\n",
    "        # There is only one class (selected node) in the TSP, so only take the first part of the action tuple\n",
    "        action = action[0]\n",
    "\n",
    "        # Append the selected city to the solution\n",
    "        state.solutions = torch.cat([state.solutions, action.unsqueeze(2)], dim=2)\n",
    "        # state.solutions.shape: (batch_size, pomo_size, 0~problem_size)\n",
    "        return state\n",
    "\n",
    "    def _update_mask(self, state: State, action: Tuple[torch.Tensor, torch.Tensor]) -> State:\n",
    "        \"\"\"\n",
    "        This function is used to update the mask based on the selected actions (cities).\n",
    "        \"\"\"\n",
    "        # There is only one class (selected node) in the TSP, so only take the first part of the action tuple\n",
    "        action = action[0]\n",
    "\n",
    "        # Initialize indices for batch and POMO dimensions\n",
    "        batch_range = torch.arange(state.batch_size, device=state.device)[:, None].expand(state.batch_size, state.pomo_size)\n",
    "        pomo_range = torch.arange(state.pomo_size, device=state.device)[None, :].expand(state.batch_size, state.pomo_size)\n",
    "\n",
    "        # Mask the selected city\n",
    "        state.mask[batch_range, pomo_range, action, :] = float('-inf')\n",
    "        return state\n",
    "\n",
    "    def _check_completeness(self, state: State) -> State:\n",
    "        \"\"\"\n",
    "        This function is used to check if the solution is complete.\n",
    "        \"\"\"\n",
    "        # Solution is complete if all cities are visited\n",
    "        state.is_complete = (state.solutions.size(2) == state.problem_size)\n",
    "        return state\n"
   ],
   "id": "828e83642e78ace5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2) Define the environment, the model, and the trainer\n",
    "tsp_problem = TSPConstructiveProblem(device=device)\n",
    "\n",
    "# Now, we define the environment for the TSP (permutation) using a constructive mode\n",
    "tsp_env = Env(problem=tsp_problem,\n",
    "              reward=ConstructiveReward(),\n",
    "              stopping_criteria=ConstructiveStoppingCriteria(),\n",
    "              device=device)\n",
    "\n",
    "# Define the model based on 2 node features (2D coordinates)\n",
    "tsp_model = GTModel(decoder='attention', node_in_dim=6, aux_node=True, logit_clipping=10.0).to(device)\n",
    "\n",
    "# Define the RL training algorithm\n",
    "tsp_trainer = ConstructiveTrainer(model=tsp_model,\n",
    "                                  env=tsp_env,\n",
    "                                  optimizer=torch.optim.Adam(tsp_model.parameters(), lr=5e-4),\n",
    "                                  device=device)"
   ],
   "id": "d37a922b742bc7f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3) Run training and inference for the Traveling Salesman Problem\n",
    "train_results = tsp_trainer.train(epochs=10, episodes=10, problem_size=20, batch_size=64, pomo_size=1,\n",
    "                                  eval_problem_size=20, eval_batch_size=256, baseline_type='mean', verbose=True)\n",
    "\n",
    "tsp_trainer.inference(problem_size=20, batch_size=100, pomo_size=1, deterministic=True, seed=42, verbose=True)"
   ],
   "id": "4c2522e3698d71f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Example for the Traveling Salesman Problem (TSP), training an improvement model\n",
    "1) Define the TSP improvement problem\n",
    "2) Define the environment, the model, and the trainer\n",
    "3) Run training and inference"
   ],
   "id": "5e508ac1bd7abf28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1) Define the TSP improvement problem\n",
    "class TSPImprovementProblem(ImprovementProblem):\n",
    "    def _init_instances(self, state: State) -> State:\n",
    "        \"\"\"\n",
    "        Here the user can define the generation of the instances for the TSP problem.\n",
    "        These instances will be later used to define the node/edge features.\n",
    "        The state class supports the adjacency matrix as a default data field.\n",
    "        If any other data is needed, it should be stored in the state.data dictionary as done with the coordinates.\n",
    "        The instances will generally have a shape of (batch_size, problem_size, problem_size, n) or (batch_size, problem_size, n), where n is the number of features.\n",
    "        \"\"\"\n",
    "        if state.seed is not None:\n",
    "            torch.manual_seed(state.seed)\n",
    "\n",
    "        # Generate the city coordinates as user-defined data\n",
    "        state.data['coords'] = torch.rand(state.batch_size, state.problem_size, 2, device=state.device)\n",
    "\n",
    "        # Also define the Euclidean distances to later be used as edge features\n",
    "        state.data['distances'] = torch.cdist(state.data['coords'], state.data['coords'])\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _init_solutions(self, state: State) -> State:\n",
    "        \"\"\"\n",
    "        Here the user can define the initialization of the solutions for the TSP problem.\n",
    "        In improvement methods, the solutions are generally initialized as complete solutions.\n",
    "        The user can initialize multiple solutions per instance (with POMO).\n",
    "        The solution will generally have a shape of (batch_size, pomo_size, problem_size).\n",
    "        \"\"\"\n",
    "        # Set random seed if defined\n",
    "        if state.seed is not None:\n",
    "            torch.manual_seed(state.seed)\n",
    "\n",
    "        # Initialize the solutions as random permutations\n",
    "        state.solutions = torch.stack(\n",
    "            [torch.randperm(state.problem_size, device=state.device) for _ in range(state.batch_size*state.pomo_size)])\n",
    "\n",
    "        # Reshape the solutions to have the POMO dimension\n",
    "        state.solutions = state.solutions.view(state.batch_size, state.pomo_size, state.problem_size)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _init_features(self, state: State) -> State:\n",
    "        \"\"\"\n",
    "        Here the user can define the initialization of the node features for the TSP problem.\n",
    "\n",
    "        For the improvement method, the init_features and update_features will be the same, so we call it from here\n",
    "        \"\"\"\n",
    "        action = (torch.empty(0), torch.empty(0))\n",
    "        return self._update_features(state, action)\n",
    "\n",
    "    def _init_mask(self, state: State) -> State:\n",
    "        \"\"\"\n",
    "        Here the user can define the initialization of the mask.\n",
    "        In the improvement method for the TSP, we will mask the diagonal elements to avoid self-loops.\n",
    "        \"\"\"\n",
    "\n",
    "        # Mask the diagonal elements.\n",
    "        mask = torch.zeros((state.batch_size, state.pomo_size, state.problem_size, state.problem_size, 1), device=state.device)\n",
    "        row_indices = torch.arange(state.problem_size, device=state.device)\n",
    "        mask[:, :, row_indices, row_indices, :] = -float('inf')\n",
    "        # Reshape the mask to (batch_size, problem_size^2, 1)\n",
    "        state.mask = mask.reshape(state.batch_size, state.pomo_size, -1, 1)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _obj_function(self, state: State) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        In this function, the user needs to define the objective function for the TSP problem.\n",
    "        This function is called every improvement step.\n",
    "        \"\"\"\n",
    "        gathering_index = state.solutions.unsqueeze(3).expand(state.batch_size, state.pomo_size, state.problem_size, 2)\n",
    "        # shape: (batch, pomo, problem, 2)\n",
    "\n",
    "        seq_expanded = state.data['coords'][:, None, :, :].expand(state.batch_size, state.pomo_size, state.problem_size, 2)\n",
    "        # shape: (batch, pomo, problem, 2)\n",
    "\n",
    "        ordered_seq = seq_expanded.gather(dim=2, index=gathering_index)\n",
    "        # shape: (batch, pomo, problem, 2)\n",
    "\n",
    "        rolled_seq = ordered_seq.roll(dims=2, shifts=-1)\n",
    "        segment_lengths = ((ordered_seq-rolled_seq)**2).sum(3).sqrt()\n",
    "        # shape: (batch, pomo, problem)\n",
    "\n",
    "        travel_distances = segment_lengths.sum(2)\n",
    "\n",
    "        return -travel_distances  # minimize the total distance  -> maximize the negative distance\n",
    "\n",
    "    def _update_features(self, state: State, action: Tuple[torch.Tensor, torch.Tensor]) -> State:\n",
    "        \"\"\"\n",
    "        This function is used to define how to update the node/edge features based on the new partial solutions.\n",
    "        \"\"\"\n",
    "        # Initialize indices for batch and POMO dimensions\n",
    "        batch_pomo_range = torch.arange(state.batch_size*state.pomo_size, device=state.device)\n",
    "\n",
    "        # Use the 2D coordinates as node features\n",
    "        state.node_features = state.data['coords'].unsqueeze(1).expand(state.batch_size, state.pomo_size, state.problem_size, 2)\n",
    "\n",
    "        # Initialize edge solutions tensor\n",
    "        edge_solutions = torch.zeros(state.batch_size*state.pomo_size, state.problem_size, state.problem_size,\n",
    "                                     dtype=torch.float32, device=device)\n",
    "\n",
    "        # Update edge solutions using advanced indexing\n",
    "        solutions = state.solutions.view(-1, state.problem_size)  # shape: (batch_size*pomo_size, problem_size)\n",
    "        solutions_plus_one = torch.cat([solutions[:, 1:], solutions[:, :1]], dim=1)\n",
    "        edge_solutions[batch_pomo_range.unsqueeze(-1), solutions, solutions_plus_one] = 1\n",
    "\n",
    "        # Make the edge solutions symmetric\n",
    "        #edge_solutions = edge_solutions + edge_solutions.permute(0, 2, 1)\n",
    "\n",
    "        # One-hot encoding of the edge solutions\n",
    "        edge_solutions = F.one_hot(edge_solutions.long(), 2).float()\n",
    "\n",
    "        # Reshape the edge solutions to have the POMO dimension\n",
    "        edge_solutions = edge_solutions.view(state.batch_size, state.pomo_size, state.problem_size, state.problem_size, 2)\n",
    "\n",
    "        # Use the distances as edge features\n",
    "        distances = state.data['distances'].unsqueeze(1).expand(state.batch_size, state.pomo_size, state.problem_size, state.problem_size)\n",
    "        state.edge_features = torch.cat([distances.unsqueeze(-1), edge_solutions], dim=-1)\n",
    "        return state\n",
    "\n",
    "    def _update_solutions(self, state: State, action: Tuple[torch.Tensor, torch.Tensor]) -> State:\n",
    "        \"\"\"\n",
    "        This function is used to update the solutions based on the selected actions.\n",
    "        Actions are given in a tuple format, where the first part is the selected node and the second part is the selected class.\n",
    "        In the case of the TSP, we only need the selected pair of nodes (edge); this is equivalent to having a single class.\n",
    "        Therefore, only the first part of the action tuple is used.\n",
    "        \"\"\"\n",
    "        action = action[0]\n",
    "\n",
    "        # Update the solutions using the 2-opt action\n",
    "        #state.solutions = two_opt(state.solutions, action)\n",
    "        state.solutions = insert(state.solutions, action)\n",
    "        #state.solutions = swap(state.solutions, action)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _update_mask(self, state: State, action: Tuple[torch.Tensor, torch.Tensor]) -> State:\n",
    "        \"\"\"\n",
    "        This function is used to update the mask based on the selected actions (cities).\n",
    "        \"\"\"\n",
    "        # The mask is static (only mask the diagonal elements), so no update is needed\n",
    "        return state\n",
    "\n",
    "    def _check_completeness(self, state: State) -> State:\n",
    "        \"\"\"\n",
    "        This function is used to check if the solution is complete.\n",
    "        \"\"\"\n",
    "        # In improvement problems, the solution is always complete\n",
    "        state.is_complete = True\n",
    "        return state\n"
   ],
   "id": "8fd22663acf0319c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2) Define the environment, the model, and the trainer\n",
    "tsp_problem = TSPImprovementProblem(device=device)\n",
    "\n",
    "# Now, we define the environment for the TSP (permutation) using a constructive mode\n",
    "tsp_env = Env(problem=tsp_problem,\n",
    "              reward=ImprovementReward(positive_only=False, normalize=True),\n",
    "              stopping_criteria=ImprovementStoppingCriteria(max_steps=200, patience=5),\n",
    "              device=device)\n",
    "\n",
    "# Define the model based on 2 node features (2D coordinates) and\n",
    "tsp_model = EdgeInOutGTModel(decoder='edge', node_in_dim=2, edge_in_dim=3, edge_out_dim=1, aux_node=False,\n",
    "                             logit_clipping=10.0).to(device)\n",
    "\n",
    "# Define the RL training algorithm\n",
    "tsp_trainer = ImprovementTrainer(model=tsp_model,\n",
    "                                 env=tsp_env,\n",
    "                                 optimizer=torch.optim.Adam(tsp_model.parameters(), lr=5e-4),\n",
    "                                 device=device)"
   ],
   "id": "bfd1d2493ec6ae8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3) Run training and inference for the Traveling Salesman Problem\n",
    "train_results = tsp_trainer.train(epochs=10, episodes=100, problem_size=20, batch_size=64, pomo_size=1,\n",
    "                                  eval_problem_size=20, eval_batch_size=256, baseline_type='mean', verbose=True)\n",
    "\n",
    "tsp_trainer.inference(problem_size=20, batch_size=100, pomo_size=1, deterministic=True, seed=42, verbose=True)"
   ],
   "id": "c869091d8f151e69"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Example for the Maximum Cut problem (MC), training a constructive model\n",
    "1) Define the MC constructive problem\n",
    "2) Define the environment, the model, and the trainer\n",
    "3) Run training and inference"
   ],
   "id": "86eb0751e0cd7db5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1) Define the MC constructive problem\n",
    "class MCConstructiveProblem(ConstructiveProblem):\n",
    "    def _init_instances(self, state: State) -> State:\n",
    "        state.adj_matrix = generate_random_graph(state.batch_size, state.problem_size, state.seed, edge_prob=0.15, device=device)\n",
    "        return state\n",
    "\n",
    "    def _init_solutions(self, state: State) -> State:\n",
    "        state.solutions = torch.zeros((state.batch_size, state.problem_size), device=state.device)\n",
    "        return state\n",
    "\n",
    "    def _init_features(self, state: State) -> State:\n",
    "        # Generate the node features, we will use the three states of the solutions as node features (two classes and one for unassigned)\n",
    "        state.node_features = F.one_hot(state.solutions.long(), 3).float()\n",
    "        # Use adjacency matrix as edge features\n",
    "        state.edge_features = state.adj_matrix.unsqueeze(-1)\n",
    "        return state\n",
    "\n",
    "    def _init_mask(self, state: State) -> State:\n",
    "        state.mask = torch.zeros((state.batch_size, state.problem_size, 2), device=state.device)\n",
    "        return state\n",
    "\n",
    "    def _obj_function(self, state: State) -> torch.Tensor:\n",
    "        batch_size, N = state.solutions.shape\n",
    "        obj_values = torch.zeros(batch_size, device=device)\n",
    "        ising_solutions = state.solutions.clone()\n",
    "        ising_solutions[ising_solutions == 1] = -1\n",
    "        ising_solutions[ising_solutions == 2] = 1\n",
    "        for b in range(batch_size):\n",
    "            obj_values[b] = (1 / 4) * torch.sum(\n",
    "                torch.mul(state.adj_matrix[b], 1 - torch.outer(ising_solutions[b], ising_solutions[b])))\n",
    "        return obj_values\n",
    "\n",
    "    def _update_features(self, state: State) -> State:\n",
    "        # Update the node features, we will use the three states of the solutions as node features (two classes and one for unassigned)\n",
    "        state.node_features = F.one_hot(state.solutions.long(), 3).float()\n",
    "        return state\n",
    "\n",
    "    def _update_solutions(self, state: State, action: torch.Tensor) -> State:\n",
    "        classes = action % 2\n",
    "        nodes = action // 2\n",
    "        batch_range = torch.arange(state.batch_size, device=state.device)\n",
    "        state.solutions[batch_range, nodes] = classes.float() + 1\n",
    "        return state\n",
    "\n",
    "    def _update_mask(self, state: State, action: torch.Tensor) -> State:\n",
    "        nodes = action // 2\n",
    "        batch_range = torch.arange(state.batch_size, device=state.device)\n",
    "        state.mask[batch_range, nodes, :] = float('-inf')\n",
    "        return state\n",
    "\n",
    "    def _check_completeness(self, state: State) -> State:\n",
    "        state.is_complete = (state.solutions == 0).sum() == 0\n",
    "        return state\n"
   ],
   "id": "a534459a65760806"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2) Define the environment, the model, and the trainer\n",
    "mc_problem = MCConstructiveProblem(device=device)\n",
    "\n",
    "# Now, we define the environment for the MC\n",
    "mc_env = Env(problem=mc_problem,\n",
    "             reward=ConstructiveReward(),\n",
    "             stopping_criteria=ConstructiveStoppingCriteria(),\n",
    "             device=device)\n",
    "\n",
    "# Define the model based on edge features (adjacency matrix)\n",
    "mc_model = EdgeInGTModel(node_in_dim=3, node_out_dim=2, edge_in_dim=1).to(device)\n",
    "\n",
    "# Define the RL training algorithm\n",
    "mc_trainer = ConstructiveTrainer(model=mc_model, env=mc_env, optimizer=torch.optim.Adam(mc_model.parameters()),\n",
    "                                 device=device)"
   ],
   "id": "7b2b3c6bb6686b58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3) Run training and inference for the Maximum Cut Problem (MC)\n",
    "mc_trainer.train(epochs=10, episodes=10, problem_size=20, batch_size=32, save_freq=10, verbose=True)\n",
    "mc_trainer.inference(problem_size=20, batch_size=100, deterministic=True, seed=42, verbose=True)"
   ],
   "id": "2bbb424106e82061"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Example for the Maximum Independent Set problem (MIS), training an improvement model\n",
    "1) Define the MIS improvement problem\n",
    "2) Define the environment, the model, and the trainer\n",
    "3) Run training and inference"
   ],
   "id": "461f667526b76968"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1) Define the MIS improvement problem\n",
    "class MISImprovementProblem(ImprovementProblem):\n",
    "    def _init_instances(self, state: State) -> State:\n",
    "        state.adj_matrix = generate_random_graph(state.batch_size, state.problem_size, state.seed, edge_prob=0.15, device=device)\n",
    "        return state\n",
    "\n",
    "    def _init_solutions(self, state: State) -> State:\n",
    "        if state.seed is not None:\n",
    "            random.seed(state.seed)\n",
    "        # Generate the initial solutions\n",
    "        solutions = torch.zeros(state.batch_size, state.problem_size, device=device)\n",
    "\n",
    "        # Precompute the neighbors for each node in each graph\n",
    "        neighbors = [torch.nonzero(state.adj_matrix[b], as_tuple=False) for b in range(state.batch_size)]\n",
    "        for b in range(state.batch_size):\n",
    "            available_nodes = set(range(state.problem_size))\n",
    "            node_neighbors = neighbors[b]\n",
    "            while available_nodes:\n",
    "                node = random.sample(list(available_nodes), 1)[0]\n",
    "                # Vectorized check for independent set condition\n",
    "                if not torch.any((state.adj_matrix[b, node] == 1) & (solutions[b] == 1)):\n",
    "                    solutions[b, node] = 1\n",
    "                    # Remove the node and its neighbors\n",
    "                    neighbor_nodes = node_neighbors[node_neighbors[:, 0] == node][:, 1]\n",
    "                    available_nodes -= {node, *neighbor_nodes.tolist()}\n",
    "                else:\n",
    "                    available_nodes.remove(node)\n",
    "\n",
    "        state.solutions = solutions\n",
    "        return state\n",
    "\n",
    "    def _init_features(self, state: State) -> State:\n",
    "        # Generate the node weights, we will use a weight of 1 for all nodes\n",
    "        state.node_features = F.one_hot(state.solutions.long(), 2).float()\n",
    "        # Use adjacency matrix as edge features\n",
    "        state.edge_features = state.adj_matrix.unsqueeze(-1)\n",
    "        return state\n",
    "\n",
    "    def _init_mask(self, state: State) -> State:\n",
    "        return self._update_mask(state, None)\n",
    "\n",
    "    def _obj_function(self, state: State) -> torch.Tensor:\n",
    "        return state.solutions.sum(1).float()\n",
    "\n",
    "    def _update_features(self, state: State) -> State:\n",
    "        # Generate the node weights, we will use a weight of 1 for all nodes\n",
    "        state.node_features = F.one_hot(state.solutions.long(), 2).float()\n",
    "        return state\n",
    "\n",
    "    def _update_solutions(self, state: State, action: torch.Tensor) -> State:\n",
    "        state.solutions = bit_flip(state.solutions, action)\n",
    "        return state\n",
    "\n",
    "    def _update_mask(self, state: State, action: torch.Tensor or None) -> State:\n",
    "        # Use batch matrix multiplication to find if any adjacent node is in the set\n",
    "        adjacent_mask = torch.bmm(state.edge_features.squeeze(-1), state.solutions.unsqueeze(2).float()).squeeze(2)\n",
    "\n",
    "        # Nodes that can't be added (any adjacent node is in the set)\n",
    "        mask = torch.zeros(state.batch_size, state.problem_size, device=device)\n",
    "        masked_index = (adjacent_mask > 0) & (state.solutions == 0)\n",
    "        mask[masked_index] = float('-inf')\n",
    "        state.mask = mask.unsqueeze(-1)\n",
    "        return state\n",
    "\n",
    "    def _check_completeness(self, state: State) -> State:\n",
    "        state.is_complete = True\n",
    "        return state"
   ],
   "id": "7d9519cfab57059c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2) Define the environment, the model, and the trainer\n",
    "mis_problem = MISImprovementProblem(device=device)\n",
    "\n",
    "mis_env = Env(problem=mis_problem,\n",
    "              reward=ImprovementReward(),\n",
    "              stopping_criteria=ImprovementStoppingCriteria(max_steps=20, patience=3),\n",
    "              device=device)\n",
    "\n",
    "# Define the model based on edge features (adjacency matrix)\n",
    "mis_model = EdgeInGTModel(node_in_dim=2, node_out_dim=1, edge_in_dim=1).to(device)\n",
    "\n",
    "# Define the RL training algorithm\n",
    "mis_trainer = ImprovementTrainer(model=mis_model,\n",
    "                                 env=mis_env,\n",
    "                                 optimizer=torch.optim.Adam(mis_model.parameters(), lr=1e-3),\n",
    "                                 device=device)"
   ],
   "id": "2c43bfc3dffa4920"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3) Run training and inference for the Maximum Independent Set Problem (MIS)\n",
    "mis_trainer.train(epochs=10, episodes=10, problem_size=20, batch_size=32, save_freq=10, verbose=True)\n",
    "mis_trainer.inference(problem_size=20, batch_size=100, deterministic=True, seed=42, verbose=True)"
   ],
   "id": "d8ea4e4da3161bf9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
